<launch>

    <!-- Launch usb-cam node -->
    <!-- <node name="usb_cam" pkg="usb_cam" type="usb_cam_node" launch-prefix="xterm -e">

        <param name="video_device" value="/dev/video0" />

        <param name="image_width" value="640" />

        <param name="image_height" value="480" />
 
        <param name="pixel_format" value="mjpeg" />
  
        <param name="camera_frame_id" value="usb_cam" />
  
        <param name="io_method" value="mmap"/>

    </node> -->


    <node pkg="yolov8_ros" type="yolo_ros.py" name="yolov8_node" output="screen">

        <!-- Download the official weights from the original repo -->
        <!-- <param name="weights_path" type="str" value="/home/vboxuser/new_ws/src/yolov8_ros/model/yolov8n.pt"/> -->

        <!-- Path to a class_labels.txt file containing your desired class labels. The i-th entry corresponds to the i-th class id. For example, in coco class label 0 corresponds to 'person'. Files for the coco and berkeley deep drive datasets are provided in the 'class_labels/' directory. If you leave it empty then no class labels are visualized.-->
        <!-- <param name="classes_path" type="str" value="/home/vboxuser/new_ws/src/yolov8_ros/model/coco.txt" /> -->

        <!-- topic name to subscribe to -->
        <param name="img_topic" type="str" value="/camera/rgb/image_raw" />

        <!-- topic name for the detection output -->
        <param name="center_depth_topic" type="str" value="/camera/depth/image_raw" />

        <param name="queue_size" type="int" value="1" />

        <!-- flag whether to also publish image with the visualized detections -->
        <param name="visualize" type="bool" value="True" />
 
    </node>
</launch>
